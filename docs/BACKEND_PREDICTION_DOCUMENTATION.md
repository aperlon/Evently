# ğŸ“š DocumentaciÃ³n Completa del Backend de Predicciones - Evently

Este documento explica **todos los archivos** relacionados con la generaciÃ³n de predicciones en el backend, cÃ³mo funcionan y cÃ³mo se relacionan entre sÃ­.

---

## ğŸ“ Estructura de Archivos

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ endpoints.py          # Endpoints de la API (incluye /predict)
â”‚   â”‚   â””â”€â”€ schemas.py            # Esquemas de validaciÃ³n (Pydantic)
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ economic_impact_model.py  # â­ MODELO PRINCIPAL DE ML
â”‚   â”‚   â””â”€â”€ __init__.py           # Exportaciones del mÃ³dulo ML
â”‚   â””â”€â”€ main.py                   # AplicaciÃ³n FastAPI principal
â”‚
data/examples/
â”œâ”€â”€ cities.csv                    # Datos de ciudades
â”œâ”€â”€ events.csv                    # Datos de eventos histÃ³ricos
â”œâ”€â”€ event_impacts.csv            # Impactos econÃ³micos histÃ³ricos (TARGET)
â”œâ”€â”€ tourism_metrics.csv          # â­ MÃ©tricas diarias de turismo (time-series)
â”œâ”€â”€ hotel_metrics.csv            # â­ MÃ©tricas diarias de hoteles (time-series)
â”œâ”€â”€ economic_metrics.csv         # â­ MÃ©tricas diarias econÃ³micas (time-series)
â””â”€â”€ mobility_metrics.csv         # â­ MÃ©tricas diarias de movilidad (time-series)
```

---

## ğŸ¯ Flujo General del Sistema

```
1. Usuario hace request â†’ POST /api/v1/predict
2. FastAPI recibe request â†’ endpoints.py
3. Valida datos â†’ schemas.py (PredictionInput)
4. Obtiene modelo ML â†’ get_ml_model() (singleton)
5. Modelo busca eventos similares â†’ predict_simple()
6. Modelo genera predicciÃ³n â†’ predict()
7. Calcula KPIs adicionales â†’ breakdown, estimates, baseline
8. Retorna respuesta â†’ schemas.py (PredictionResponse)
```

---

## ğŸ“„ ARCHIVO 1: `backend/app/api/endpoints.py`

**PropÃ³sito**: Define todos los endpoints de la API REST, incluyendo el endpoint de predicciÃ³n.

### SecciÃ³n Clave: InicializaciÃ³n del Modelo ML

```python
# LÃ­neas 19-50: Singleton del modelo ML
_ml_model = None  # Variable global para mantener una sola instancia

def get_ml_model() -> EconomicImpactModel:
    """
    PatrÃ³n Singleton: Solo crea UNA instancia del modelo en toda la aplicaciÃ³n.
    Esto es importante porque:
    - El modelo es pesado (tiene que cargar datos CSV)
    - Entrenar el modelo toma tiempo
    - Queremos reutilizar el modelo entrenado
    """
    global _ml_model
    if _ml_model is None:
        # Primera vez: crear instancia
        _ml_model = EconomicImpactModel()
        try:
            # Intentar cargar modelo pre-entrenado
            _ml_model.load()
            if _ml_model.best_model is None:
                raise FileNotFoundError("Model file exists but is invalid")
        except (FileNotFoundError, Exception) as e:
            # Si no existe o estÃ¡ corrupto, entrenar desde cero
            print(f"âš ï¸  Model not found or invalid: {e}")
            print("ğŸ”„ Training model from CSV data...")
            try:
                _ml_model.load_data()  # Cargar CSVs
                _ml_model.train()      # Entrenar modelos
                _ml_model.save()       # Guardar para prÃ³xima vez
                print("âœ… Model trained and saved successfully")
            except Exception as train_error:
                print(f"âŒ Error training model: {train_error}")
                raise ValueError(f"Could not train model: {train_error}")
    
    # Verificar que el modelo estÃ¡ listo
    if _ml_model.best_model is None:
        raise ValueError("Model is not trained...")
    
    return _ml_model
```

### Endpoint Principal: `/predict`

```python
# LÃ­neas 514-555: Endpoint de predicciÃ³n
@router.post("/predict", response_model=schemas.PredictionResponse)
def predict_event_impact(input_data: schemas.PredictionInput):
    """
    Endpoint principal para hacer predicciones.
    
    Input mÃ­nimo requerido:
    - event_type: "sports", "music", "festival", "culture"
    - city: "London", "Tokyo", etc. (debe existir en cities.csv)
    - duration_days: 1-365 dÃ­as
    - attendance: OPCIONAL (se estima si no se proporciona)
    
    Proceso:
    1. Obtiene el modelo ML (singleton)
    2. Verifica que estÃ© entrenado
    3. Llama a predict_simple() que:
       - Busca eventos histÃ³ricos similares
       - Estima parÃ¡metros faltantes
       - Genera predicciÃ³n
       - Calcula baseline comparison
    4. Retorna resultado completo
    """
    try:
        model = get_ml_model()  # Obtener modelo (singleton)
        
        # Verificar que el modelo estÃ© listo
        if model.best_model is None:
            # Si no estÃ¡ entrenado, entrenarlo ahora
            print("âš ï¸  Model not ready, attempting to train...")
            model.load_data()
            model.train()
            model.save()
        
        # Hacer predicciÃ³n usando mÃ©todo "simple" (auto-estima parÃ¡metros)
        result = model.predict_simple(
            event_type=input_data.event_type,
            city=input_data.city,
            duration_days=input_data.duration_days,
            attendance=input_data.attendance  # Puede ser None
        )
        return result
    except ValueError as e:
        # Error de validaciÃ³n (ciudad no encontrada, etc.)
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        # Error interno del servidor
        raise HTTPException(status_code=500, detail=f"Error making prediction: {str(e)}")
```

### Endpoint Alternativo: `/predict/detailed`

```python
# LÃ­neas 558-605: Endpoint con parÃ¡metros avanzados
@router.post("/predict/detailed")
def predict_event_impact_detailed(...):
    """
    Endpoint avanzado que permite sobrescribir parÃ¡metros estimados.
    
    Ãštil cuando el usuario tiene datos especÃ­ficos sobre:
    - visitor_increase_pct: Incremento de visitantes conocido
    - price_increase_pct: Incremento de precios conocido
    - occupancy_boost: Boost de ocupaciÃ³n conocido
    
    Si se proporcionan estos parÃ¡metros, usa predict() directamente.
    Si no, usa predict_simple() que los estima.
    """
```

---

## ğŸ“„ ARCHIVO 2: `backend/app/api/schemas.py`

**PropÃ³sito**: Define los esquemas de validaciÃ³n Pydantic para requests y responses.

### Esquema de Input: `PredictionInput`

```python
# LÃ­neas 304-309: Input del usuario
class PredictionInput(BaseModel):
    """
    Esquema que valida los datos que envÃ­a el frontend.
    
    Campos:
    - event_type: str (debe ser uno de los tipos vÃ¡lidos)
    - city: str (debe existir en cities.csv)
    - duration_days: int (1-365, validado con ge=1, le=365)
    - attendance: Optional[int] (opcional, >= 0)
    
    Pydantic valida automÃ¡ticamente:
    - Tipos de datos
    - Rangos (ge=greater or equal, le=less or equal)
    - Campos requeridos vs opcionales
    """
    event_type: str = Field(..., description="Type: sports, music, festival, culture")
    city: str = Field(..., description="City name from available cities")
    duration_days: int = Field(..., ge=1, le=365, description="Event duration in days")
    attendance: Optional[int] = Field(None, ge=0, description="Expected attendance (optional)")
```

### Esquema de Output: `PredictionResponse`

```python
# LÃ­neas 358-366: Respuesta completa
class PredictionResponse(BaseModel):
    """
    Estructura de la respuesta que se envÃ­a al frontend.
    
    Contiene:
    - prediction: Resultado principal (impacto, lÃ­mites, confianza)
    - breakdown: Desglose econÃ³mico (directo, indirecto, inducido)
    - estimates: Estimaciones adicionales (empleos, ROI, costo)
    - baseline_comparison: ComparaciÃ³n con semana normal
    - model_info: InformaciÃ³n del modelo (RÂ², MAPE, algoritmo usado)
    - input_summary: Resumen de inputs usados
    """
    prediction: PredictionResult
    breakdown: PredictionBreakdown
    estimates: PredictionEstimates
    historical_reference: Optional[HistoricalReference] = None
    baseline_comparison: Optional[BaselineComparison] = None
    model_info: Dict[str, Any]
    input_summary: Dict[str, Any]
```

---

## ğŸ“„ ARCHIVO 3: `backend/app/ml/economic_impact_model.py` â­ **ARCHIVO PRINCIPAL**

**PropÃ³sito**: Contiene toda la lÃ³gica del modelo de Machine Learning.

### Clase Principal: `EconomicImpactModel`

```python
# LÃ­neas 23-85: InicializaciÃ³n
class EconomicImpactModel:
    """
    Modelo de regresiÃ³n para predecir impacto econÃ³mico de eventos.
    
    CaracterÃ­sticas:
    - Lee datos desde archivos CSV (fÃ¡cil de actualizar)
    - Entrena mÃºltiples algoritmos y selecciona el mejor
    - Guarda el modelo entrenado para reutilizaciÃ³n
    - Auto-estima parÃ¡metros faltantes usando eventos histÃ³ricos similares
    """
    
    def __init__(self, data_dir: str = None):
        """
        Inicializa el modelo.
        
        Busca el directorio de datos en varios lugares posibles:
        1. data/examples/ (relativo al proyecto)
        2. /data/examples/ (Docker)
        3. /home/user/Evently/data/examples/ (producciÃ³n)
        
        Inicializa:
        - DataFrames para almacenar CSVs
        - Diccionario de modelos (para probar varios algoritmos)
        - Scaler (para normalizar features)
        - Label encoders (para codificar tipos de eventos)
        - Feature columns (lista de variables que usa el modelo)
        """
```

### MÃ©todo 1: `load_data()` - Cargar Datos CSV

```python
# LÃ­neas 86-133: Cargar CSVs
def load_data(self) -> pd.DataFrame:
    """
    Carga los 7 archivos CSV (3 bÃ¡sicos + 4 de mÃ©tricas time-series):
    
    CSVs BÃSICOS:
    1. events.csv: InformaciÃ³n de eventos histÃ³ricos
       - event_name, city, event_type, start_date, end_date, etc.
    
    2. cities.csv: InformaciÃ³n de ciudades
       - name, country, population, annual_tourists, hotel_rooms, etc.
    
    3. event_impacts.csv: â­ TARGET VARIABLE (lo que queremos predecir)
       - event_name, city, total_economic_impact_usd, etc.
    
    CSVs DE MÃ‰TRICAS TIME-SERIES (â­ NUEVOS):
    4. tourism_metrics.csv: Datos diarios de turismo
       - city, date, total_visitors, avg_spending_per_visitor_usd, etc.
       - Miles de registros diarios por ciudad
    
    5. hotel_metrics.csv: Datos diarios de hoteles
       - city, date, occupancy_rate_pct, avg_price_usd, etc.
       - Datos diarios de ocupaciÃ³n y precios
    
    6. economic_metrics.csv: Datos diarios de gasto econÃ³mico
       - city, date, total_spending_usd, accommodation_spending_usd, etc.
       - Desglose diario de gasto por categorÃ­a
    
    7. mobility_metrics.csv: Datos diarios de movilidad
       - city, date, airport_arrivals, public_transport_usage, etc.
       - MÃ©tricas de transporte y movilidad
    
    Luego llama a _prepare_training_data() que:
    - Hace merge de los CSVs bÃ¡sicos
    - Enriquece cada evento con mÃ©tricas de los CSVs time-series
    - Crea features derivadas (promedios, diferencias, ratios)
    - Limpia datos faltantes
    """
    # Load basic CSVs
    self.df_events = pd.read_csv(self.data_dir / "events.csv")
    self.df_cities = pd.read_csv(self.data_dir / "cities.csv")
    self.df_impacts = pd.read_csv(self.data_dir / "event_impacts.csv")
    
    # Load time-series metrics CSVs
    self.df_tourism_metrics = pd.read_csv(self.data_dir / "tourism_metrics.csv")
    self.df_hotel_metrics = pd.read_csv(self.data_dir / "hotel_metrics.csv")
    self.df_economic_metrics = pd.read_csv(self.data_dir / "economic_metrics.csv")
    self.df_mobility_metrics = pd.read_csv(self.data_dir / "mobility_metrics.csv")
    
    # Convert date columns to datetime
    self.df_tourism_metrics['date'] = pd.to_datetime(self.df_tourism_metrics['date'])
    self.df_hotel_metrics['date'] = pd.to_datetime(self.df_hotel_metrics['date'])
    self.df_economic_metrics['date'] = pd.to_datetime(self.df_economic_metrics['date'])
    self.df_mobility_metrics['date'] = pd.to_datetime(self.df_mobility_metrics['date'])
    
    # Preparar datos para entrenamiento
    self.df_training = self._prepare_training_data()
    return self.df_training
```

### MÃ©todo 2: `_prepare_training_data()` - Preparar Datos

```python
# LÃ­neas 135-470: PreparaciÃ³n de datos
def _prepare_training_data(self) -> pd.DataFrame:
    """
    â­ MÃ‰TODO CRÃTICO: Prepara los datos para entrenar el modelo.
    
    Pasos:
    
    1. MERGE DE DATOS BÃSICOS:
       - Une event_impacts con cities (para obtener caracterÃ­sticas de ciudad)
       - Une con events (para obtener tipo de evento, duraciÃ³n)
    
    2. â­ ENRIQUECER CON MÃ‰TRICAS TIME-SERIES (_enrich_with_metrics):
       Para cada evento histÃ³rico:
       a) Obtiene fechas del evento (start_date, end_date)
       b) Calcula perÃ­odo baseline (30 dÃ­as antes del evento)
       c) Extrae mÃ©tricas del perÃ­odo del evento desde los 4 CSVs
       d) Extrae mÃ©tricas del perÃ­odo baseline
       e) Calcula diferencias y ratios:
          - visitor_increase_actual (desde tourism_metrics)
          - spending_increase_pct (desde tourism_metrics)
          - occupancy_boost_actual (desde hotel_metrics)
          - hotel_price_increase_actual (desde hotel_metrics)
          - daily_spending_increase_pct (desde economic_metrics)
          - airport_arrivals_increase_pct (desde mobility_metrics)
       f) Agrega ~30 nuevas features derivadas de los CSVs
    
    3. CALCULAR FEATURES FALTANTES (si no estÃ¡n en los CSVs):
       - Si falta attendance: estima desde annual_tourists
       - Si falta visitor_increase_pct: usa visitor_increase_actual o calcula
       - Si falta price_increase_pct: usa hotel_price_increase_actual o estima
       - Si falta occupancy_boost: usa occupancy_boost_actual o estima
    
    4. CREAR FEATURES DERIVADAS:
       - attendance_per_day = attendance / duration_days
       - visitors_per_hotel_room = attendance / hotel_rooms
       - city_tourism_intensity = annual_tourists / population
    
    5. ENCODING:
       - event_type â†’ event_type_encoded (LabelEncoder)
       - Convierte texto a nÃºmero para que el modelo lo entienda
    
    6. DEFINIR FEATURES FINALES (ahora ~45 variables en lugar de 13):
       Event characteristics (6):
       - attendance, duration_days, event_type_encoded
       - visitor_increase_pct, price_increase_pct, occupancy_boost
       
       City characteristics (4):
       - population, annual_tourists, hotel_rooms, avg_hotel_price_usd
       
       Derived features (3):
       - attendance_per_day, visitors_per_hotel_room, city_tourism_intensity
       
       â­ Tourism metrics (7):
       - event_avg_total_visitors, baseline_avg_total_visitors
       - visitor_increase_actual, event_avg_spending_per_visitor
       - baseline_avg_spending_per_visitor, spending_increase_pct
       - event_avg_stay_duration
       
       â­ Hotel metrics (7):
       - event_avg_occupancy_pct, baseline_avg_occupancy_pct
       - occupancy_boost_actual, event_avg_hotel_price
       - baseline_avg_hotel_price, hotel_price_increase_actual
       - event_max_hotel_price
       
       â­ Economic metrics (6):
       - event_avg_daily_spending, baseline_avg_daily_spending
       - daily_spending_increase_pct, event_avg_accommodation_spending
       - event_avg_food_spending, event_avg_retail_spending
       
       â­ Mobility metrics (7):
       - event_avg_airport_arrivals, baseline_avg_airport_arrivals
       - airport_arrivals_increase_pct, event_avg_international_flights
       - event_avg_public_transport, event_avg_traffic_congestion
       - baseline_avg_traffic_congestion
    
    7. LIMPIEZA:
       - Elimina filas sin target variable (total_economic_impact_usd)
       - Rellena valores faltantes con medianas o 0
       - Asegura que todas las features existan
    """
```

### MÃ©todo 3: `train()` - Entrenar Modelos

```python
# LÃ­neas 241-350: Entrenamiento
def train(self, test_size: float = 0.2, random_state: int = 42) -> Dict:
    """
    â­ MÃ‰TODO PRINCIPAL: Entrena mÃºltiples algoritmos y selecciona el mejor.
    
    Proceso:
    
    1. PREPARAR DATOS:
       - X = features (13 columnas)
       - y = target (total_economic_impact_usd)
       - TransformaciÃ³n logarÃ­tmica: y_log = log(1 + y)
         * Por quÃ©? El impacto econÃ³mico tiene distribuciÃ³n sesgada
         * Log transform hace la distribuciÃ³n mÃ¡s normal
         * Mejora el rendimiento del modelo
    
    2. SPLIT:
       - 80% entrenamiento, 20% testing
       - random_state=42 para reproducibilidad
    
    3. SCALING:
       - Normaliza features con StandardScaler
       - Importante para algoritmos sensibles a escala (Ridge, Lasso)
    
    4. ENTRENAR 5 ALGORITMOS:
       a) Linear Regression: Modelo simple, rÃ¡pido
       b) Ridge Regression: Linear con regularizaciÃ³n L2
       c) Lasso Regression: Linear con regularizaciÃ³n L1
       d) Random Forest: Ensemble de Ã¡rboles (suele ser el mejor)
       e) Gradient Boosting: Boosting de Ã¡rboles
    
    5. EVALUAR CADA MODELO:
       - RÂ² Score: Bondad de ajuste (0-1, mÃ¡s alto mejor)
       - MAE: Error absoluto promedio
       - RMSE: Error cuadrÃ¡tico medio
       - MAPE: Error porcentual promedio
       - Cross-validation: 5-fold CV para validar robustez
    
    6. SELECCIONAR MEJOR:
       - Elige el modelo con mayor RÂ² Score
       - Guarda como self.best_model
    
    7. FEATURE IMPORTANCE:
       - Si es modelo de Ã¡rboles, muestra quÃ© features son mÃ¡s importantes
    """
    
    # TransformaciÃ³n logarÃ­tmica del target
    y_log = np.log1p(y)  # log(1 + y) para manejar ceros
    
    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_log, test_size=0.2, random_state=42
    )
    
    # Normalizar features
    X_train_scaled = self.scaler.fit_transform(X_train)
    X_test_scaled = self.scaler.transform(X_test)
    
    # Probar 5 algoritmos
    model_configs = {
        'linear_regression': LinearRegression(),
        'ridge_regression': Ridge(alpha=1.0),
        'lasso_regression': Lasso(alpha=0.1),
        'random_forest': RandomForestRegressor(...),
        'gradient_boosting': GradientBoostingRegressor(...),
    }
    
    # Entrenar y evaluar cada uno
    for name, model in model_configs.items():
        model.fit(X_train_scaled, y_train)
        y_pred_log = model.predict(X_test_scaled)
        
        # Transformar de vuelta a escala original
        y_pred = np.expm1(y_pred_log)  # exp(y) - 1
        y_test_original = np.expm1(y_test)
        
        # Calcular mÃ©tricas
        metrics = {
            'r2': r2_score(y_test_original, y_pred),
            'mape': mean_absolute_percentage_error(...),
            ...
        }
        
        # Guardar mejor modelo
        if metrics['r2'] > best_r2:
            self.best_model = model
            self.best_model_name = name
```

### MÃ©todo 4: `predict()` - PredicciÃ³n Directa

```python
# LÃ­neas 364-490: PredicciÃ³n con parÃ¡metros completos
def predict(self, event_data: Dict) -> Dict:
    """
    Predice impacto econÃ³mico cuando tienes TODOS los parÃ¡metros.
    
    Input esperado:
    {
        'event_type': 'sports',
        'city': 'London',
        'attendance': 50000,
        'duration_days': 7,
        'visitor_increase_pct': 50.0,  # Opcional
        'price_increase_pct': 40.0,    # Opcional
        'occupancy_boost': 15.0         # Opcional
    }
    
    Proceso:
    
    1. OBTENER DATOS DE CIUDAD:
       - Busca ciudad en df_cities
       - Extrae: population, annual_tourists, hotel_rooms, avg_hotel_price_usd
    
    2. ENCODING:
       - Convierte event_type a nÃºmero usando LabelEncoder
    
    3. ESTIMAR PARÃMETROS FALTANTES (si no se proporcionan):
       - visitor_increase_pct: min(100, attendance / baseline_daily * 100)
       - price_increase_pct: min(150, visitor_increase * 0.8)
       - occupancy_boost: min(25, visitor_increase * 0.3)
    
    4. CONSTRUIR FEATURE VECTOR (13 valores):
       features = [
           attendance,
           duration_days,
           event_type_encoded,
           visitor_increase_pct,
           price_increase_pct,
           occupancy_boost,
           population,
           annual_tourists,
           hotel_rooms,
           avg_hotel_price_usd,
           attendance / duration_days,           # attendance_per_day
           attendance / hotel_rooms,            # visitors_per_hotel_room
           annual_tourists / population,        # city_tourism_intensity
       ]
    
    5. PREDECIR:
       - Normalizar features con scaler
       - Predecir en escala logarÃ­tmica
       - Transformar de vuelta: prediction = exp(pred_log) - 1
    
    6. CALCULAR INTERVALO DE CONFIANZA:
       - lower_bound = prediction * (1 - MAPE * 1.5)
       - upper_bound = prediction * (1 + MAPE * 1.5)
       - Factor 1.5 para intervalo al 90%
    
    7. CALCULAR KPIs:
       - Breakdown: 64% directo, 25% indirecto, 11% inducido
       - Jobs: prediction / 40000
       - ROI: asume 4:1 tÃ­pico
       - Cost: prediction / 4.0
    """
```

### MÃ©todo 5: `predict_simple()` - PredicciÃ³n Inteligente â­ **MÃ‰TODO MÃS IMPORTANTE**

```python
# LÃ­neas 492-704: PredicciÃ³n con auto-estimaciÃ³n
def predict_simple(self, event_type: str, city: str, duration_days: int,
                   attendance: int = None) -> Dict:
    """
    â­ MÃ‰TODO PRINCIPAL USADO POR EL FRONTEND
    
    Solo requiere inputs mÃ­nimos, el resto lo estima automÃ¡ticamente
    usando eventos histÃ³ricos similares.
    
    Proceso detallado:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 1: OBTENER DATOS DE CIUDAD                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    - Busca ciudad en cities.csv
    - Extrae: continent, country, population, annual_tourists, etc.
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 2: BUSCAR EVENTOS SIMILARES                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    - Filtra eventos del mismo tipo (event_type)
    - Filtra eventos del mismo continente (mejor match)
    - Si hay < 2 eventos del mismo continente, usa todos globalmente
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 3: CALCULAR PROMEDIOS HISTÃ“RICOS                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    De los eventos similares, calcula promedios de:
    
    a) avg_attendance_per_day:
       - attendance / duration_days para cada evento histÃ³rico
       - Promedio de todos
    
    b) avg_visitor_increase_pct:
       - visitor_increase_pct de eventos histÃ³ricos
       - O calcula desde: (attendance_per_day / baseline_daily) - 1
    
    c) avg_price_increase_pct:
       - price_increase_pct de eventos histÃ³ricos
       - O estima como: visitor_increase * 0.8
    
    d) avg_occupancy_boost:
       - occupancy_boost de eventos histÃ³ricos
       - O estima como: visitor_increase * 0.3
    
    e) avg_impact_per_day:
       - total_impact / duration_days para cada evento
       - Promedio de todos
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 4: ESTIMAR ATTENDANCE (si no se proporciona)           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    if attendance is None:
        attendance = avg_attendance_per_day * duration_days
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 5: CONSTRUIR PARÃMETROS PARA PREDICCIÃ“N                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    prediction_params = {
        'event_type': event_type,
        'city': city,
        'attendance': attendance,  # Estimado o proporcionado
        'duration_days': duration_days,
        'visitor_increase_pct': avg_visitor_increase,  # De histÃ³ricos
        'price_increase_pct': avg_price_increase,      # De histÃ³ricos
        'occupancy_boost': avg_occupancy_boost,       # De histÃ³ricos
        
        # â­ NUEVAS MÃ‰TRICAS desde los 4 CSVs adicionales:
        'event_avg_total_visitors': avg_metrics['event_avg_total_visitors'],
        'baseline_avg_total_visitors': avg_metrics['baseline_avg_total_visitors'],
        'visitor_increase_actual': avg_metrics['visitor_increase_actual'],
        'event_avg_spending_per_visitor': avg_metrics['event_avg_spending_per_visitor'],
        'baseline_avg_spending_per_visitor': avg_metrics['baseline_avg_spending_per_visitor'],
        'spending_increase_pct': avg_metrics['spending_increase_pct'],
        'event_avg_occupancy_pct': avg_metrics['event_avg_occupancy_pct'],
        'baseline_avg_occupancy_pct': avg_metrics['baseline_avg_occupancy_pct'],
        'occupancy_boost_actual': avg_metrics['occupancy_boost_actual'],
        'event_avg_hotel_price': avg_metrics['event_avg_hotel_price'],
        'baseline_avg_hotel_price': avg_metrics['baseline_avg_hotel_price'],
        'hotel_price_increase_actual': avg_metrics['hotel_price_increase_actual'],
        'event_max_hotel_price': avg_metrics['event_max_hotel_price'],
        'event_avg_daily_spending': avg_metrics['event_avg_daily_spending'],
        'baseline_avg_daily_spending': avg_metrics['baseline_avg_daily_spending'],
        'daily_spending_increase_pct': avg_metrics['daily_spending_increase_pct'],
        'event_avg_airport_arrivals': avg_metrics['event_avg_airport_arrivals'],
        'baseline_avg_airport_arrivals': avg_metrics['baseline_avg_airport_arrivals'],
        'airport_arrivals_increase_pct': avg_metrics['airport_arrivals_increase_pct'],
        # ... y mÃ¡s mÃ©tricas
    }
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 6: LLAMAR A predict() CON PARÃMETROS                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    result = self.predict(prediction_params)
    # predict() ahora construye un feature vector con ~45 features
    # (13 originales + ~32 nuevas de los CSVs de mÃ©tricas)
    # Esto genera: prediction, breakdown, estimates, model_info
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 7: CALCULAR BASELINE (semana normal sin evento)         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    baseline_daily_visitors = annual_tourists / 365
    baseline_daily_spending_per_visitor = 150  # USD (conservador)
    baseline_daily_spending = baseline_daily_visitors * 150
    baseline_period_spending = baseline_daily_spending * duration_days
    baseline_period_impact = baseline_period_spending * 1.7  # Multiplicador
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 8: CALCULAR COMPARACIÃ“N CON BASELINE                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    event_impact = result['prediction']['total_economic_impact_usd']
    additional_impact = event_impact - baseline_period_impact
    impact_multiplier = event_impact / baseline_period_impact
    impact_increase_pct = ((event_impact / baseline_period_impact) - 1) * 100
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 9: AGREGAR CONTEXTO HISTÃ“RICO                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    result['historical_reference'] = {
        'reference_scope': "Europe (5 eventos)" o "Global (12 eventos)",
        'events_analyzed': len(reference_data),
        'avg_visitor_increase_pct': avg_visitor_increase,
        'avg_price_increase_pct': avg_price_increase,
        'avg_occupancy_boost_pct': avg_occupancy_boost,
        'avg_attendance_per_day': avg_attendance_per_day,
        'avg_impact_per_day_usd': avg_impact_per_day,
        'similar_events': ['London Marathon 2024', 'Wimbledon 2024', ...],
    }
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 10: AGREGAR BASELINE COMPARISON                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    result['baseline_comparison'] = {
        'baseline_weekly_impact_usd': baseline_period_impact,
        'event_impact_usd': event_impact,
        'additional_impact_usd': additional_impact,
        'impact_multiplier': impact_multiplier,
        'impact_increase_pct': impact_increase_pct,
        'baseline_daily_visitors': baseline_daily_visitors,
        'baseline_daily_spending_usd': baseline_daily_spending,
        'duration_days': duration_days,
    }
    
    return result  # Retorna diccionario completo
    """
```

### MÃ©todos Auxiliares: `save()` y `load()`

```python
# LÃ­neas 718-776: Persistencia del modelo
def save(self, filename: str = "economic_impact_model.pkl"):
    """
    Guarda el modelo entrenado en disco.
    
    Guarda:
    - best_model: El modelo seleccionado (Random Forest, etc.)
    - best_model_name: Nombre del algoritmo
    - all_models: Todos los modelos entrenados
    - scaler: Para normalizar features nuevas
    - label_encoders: Para codificar event_type
    - feature_columns: Lista de features usadas
    - metrics: MÃ©tricas de todos los modelos
    - trained_at: Timestamp de cuÃ¡ndo se entrenÃ³
    
    UbicaciÃ³n: backend/app/ml/saved_models/economic_impact_model.pkl
    """

def load(self, filename: str = "economic_impact_model.pkl"):
    """
    Carga modelo pre-entrenado desde disco.
    
    Si el archivo existe y es vÃ¡lido, carga todo.
    Si no existe, lanza FileNotFoundError (el sistema lo entrena automÃ¡ticamente).
    """
```

---

## ğŸ“„ ARCHIVO 4: `backend/app/main.py`

**PropÃ³sito**: Punto de entrada principal de la aplicaciÃ³n FastAPI.

```python
# LÃ­neas 1-51: ConfiguraciÃ³n de FastAPI
"""
AplicaciÃ³n principal FastAPI.

Configura:
- CORS: Permite requests desde el frontend
- Routers: Incluye endpoints.py y upload.py
- DocumentaciÃ³n: Swagger UI en /docs
"""

app = FastAPI(
    title="Evently API",
    version="1.0.0",
    description="Event Impact Analyzer API"
)

# CORS para permitir frontend
app.add_middleware(CORSMiddleware, ...)

# Incluir routers
app.include_router(api_router, prefix="/api/v1")
```

---

## ğŸ“Š ARCHIVO 5: Estructura de Datos CSV

### `data/examples/cities.csv`

```csv
name,country,country_code,continent,latitude,longitude,timezone,population,area_km2,gdp_usd,annual_tourists,hotel_rooms,avg_hotel_price_usd
London,United Kingdom,GBR,Europe,51.5074,-0.1278,Europe/London,9000000,1572,635000000000,19600000,150000,180
```

**Columnas clave para predicciones:**
- `name`: Nombre de la ciudad (usado para buscar)
- `population`: PoblaciÃ³n (feature del modelo)
- `annual_tourists`: Turistas anuales (feature + cÃ¡lculo baseline)
- `hotel_rooms`: Habitaciones disponibles (feature)
- `avg_hotel_price_usd`: Precio promedio (feature)
- `continent`: Usado para filtrar eventos similares

### `data/examples/events.csv`

```csv
event_name,city,event_type,description,start_date,end_date,year,expected_attendance,actual_attendance,venue_name,venue_capacity,is_recurring,recurrence_pattern,edition_number
London Marathon 2024,London,sports,Major sports event,2024-04-21,2024-04-21,2024,50000,48000,London City Center,,1,annual,
```

**Columnas clave:**
- `event_name`: Identificador Ãºnico
- `city`: Ciudad donde ocurriÃ³
- `event_type`: Tipo (sports, music, etc.) - usado para buscar similares
- `start_date`, `end_date`: Para calcular duration_days
- `actual_attendance`: Asistencia real (si estÃ¡ disponible)

### `data/examples/event_impacts.csv` â­ **TARGET VARIABLE**

```csv
event_name,city,event_type,year,attendance,duration_days,total_economic_impact_usd,jobs_created,roi_ratio
London Marathon 2024,London,sports,2024,48000,1,9840274,480,4.73
```

**Columnas clave:**
- `event_name`: Link con events.csv
- `total_economic_impact_usd`: â­ **ESTO ES LO QUE PREDECIMOS**
- `attendance`: Asistencia (puede estar aquÃ­ o en events.csv)
- `duration_days`: DuraciÃ³n (puede calcularse desde start/end_date)
- `jobs_created`, `roi_ratio`: Datos adicionales (no se usan para entrenar)

---

## ğŸ”„ Flujo Completo de una PredicciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. FRONTEND: Usuario llena formulario                        â”‚
â”‚    - event_type: "sports"                                    â”‚
â”‚    - city: "London"                                          â”‚
â”‚    - duration_days: 7                                        â”‚
â”‚    - attendance: null (opcional)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FRONTEND: POST /api/v1/predict                            â”‚
â”‚    {                                                          â”‚
â”‚      "event_type": "sports",                                 â”‚
â”‚      "city": "London",                                       â”‚
â”‚      "duration_days": 7,                                     â”‚
â”‚      "attendance": null                                      â”‚
â”‚    }                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. BACKEND: endpoints.py - predict_event_impact()            â”‚
â”‚    - Valida con schemas.PredictionInput                      â”‚
â”‚    - Llama get_ml_model() (singleton)                        â”‚
â”‚    - Verifica que modelo estÃ© entrenado                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. BACKEND: economic_impact_model.py - predict_simple()      â”‚
â”‚                                                                
â”‚    a) Busca ciudad en cities.csv                             â”‚
â”‚       â†’ Encuentra: London, Europe, 9M pop, 19.6M tourists    â”‚
â”‚                                                                
â”‚    b) Busca eventos similares:                               â”‚
â”‚       - Tipo: sports                                         â”‚
â”‚       - Continente: Europe                                   â”‚
â”‚       â†’ Encuentra: London Marathon, Wimbledon, etc.          â”‚
â”‚                                                                
â”‚    c) Calcula promedios histÃ³ricos:                          â”‚
â”‚       - avg_attendance_per_day: 35,000                       â”‚
â”‚       - avg_visitor_increase_pct: 45%                        â”‚
â”‚       - avg_price_increase_pct: 36%                          â”‚
â”‚       - avg_occupancy_boost: 13.5%                          â”‚
â”‚                                                                
â”‚    d) Estima attendance:                                     â”‚
â”‚       attendance = 35,000 * 7 = 245,000                      â”‚
â”‚                                                                
â”‚    e) Construye feature vector (13 valores)                 â”‚
â”‚                                                                
â”‚    f) Llama predict() con parÃ¡metros                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. BACKEND: economic_impact_model.py - predict()             â”‚
â”‚                                                                
â”‚    a) Normaliza features con scaler                          â”‚
â”‚    b) Predice en escala log: pred_log = model.predict(X)     â”‚
â”‚    c) Transforma: prediction = exp(pred_log) - 1             â”‚
â”‚       â†’ $50,000,000                                          â”‚
â”‚    d) Calcula intervalos:                                    â”‚
â”‚       lower = $50M * (1 - 0.45 * 1.5) = $16.25M             â”‚
â”‚       upper = $50M * (1 + 0.45 * 1.5) = $83.75M             â”‚
â”‚    e) Calcula breakdown:                                     â”‚
â”‚       direct = $50M * 0.64 = $32M                            â”‚
â”‚       indirect = $50M * 0.25 = $12.5M                        â”‚
â”‚       induced = $50M * 0.11 = $5.5M                          â”‚
â”‚    f) Calcula estimates:                                     â”‚
â”‚       jobs = $50M / $40K = 1,250                             â”‚
â”‚       cost = $50M / 4 = $12.5M                               â”‚
â”‚       roi = 4.0x                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. BACKEND: predict_simple() - Baseline Comparison           â”‚
â”‚                                                                
â”‚    a) Calcula baseline:                                      â”‚
â”‚       daily_visitors = 19.6M / 365 = 53,699                  â”‚
â”‚       daily_spending = 53,699 * $150 = $8,054,850            â”‚
â”‚       period_spending = $8M * 7 = $56.4M                     â”‚
â”‚       baseline_impact = $56.4M * 1.7 = $95.9M                â”‚
â”‚                                                                
â”‚    b) Compara:                                                â”‚
â”‚       additional = $50M - $95.9M = -$45.9M (negativo!)       â”‚
â”‚       multiplier = $50M / $95.9M = 0.52x                     â”‚
â”‚       increase = -48%                                         â”‚
â”‚                                                                
â”‚    c) Agrega contexto histÃ³rico                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. BACKEND: Retorna respuesta completa                       â”‚
â”‚    {                                                          â”‚
â”‚      "prediction": {                                          â”‚
â”‚        "total_economic_impact_usd": 50000000,                â”‚
â”‚        "lower_bound_usd": 16250000,                           â”‚
â”‚        "upper_bound_usd": 83750000,                           â”‚
â”‚        "confidence_level": "90%"                              â”‚
â”‚      },                                                       â”‚
â”‚      "breakdown": {...},                                     â”‚
â”‚      "estimates": {...},                                     â”‚
â”‚      "baseline_comparison": {...},                           â”‚
â”‚      "historical_reference": {...},                          â”‚
â”‚      "model_info": {...}                                     â”‚
â”‚    }                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. FRONTEND: Recibe y muestra resultados                     â”‚
â”‚    - Tarjeta principal con impacto total                     â”‚
â”‚    - Desglose econÃ³mico                                      â”‚
â”‚    - Estimaciones (empleos, ROI)                             â”‚
â”‚    - ComparaciÃ³n con baseline                                â”‚
â”‚    - InformaciÃ³n del modelo                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Puntos Clave para Entender

### 1. **Por quÃ© Log Transform?**
El impacto econÃ³mico tiene distribuciÃ³n muy sesgada (algunos eventos generan $1M, otros $1B). La transformaciÃ³n logarÃ­tmica hace la distribuciÃ³n mÃ¡s normal, mejorando el rendimiento del modelo.

### 2. **Por quÃ© MÃºltiples Algoritmos?**
Diferentes algoritmos funcionan mejor con diferentes tipos de datos:
- **Linear/Ridge/Lasso**: RÃ¡pidos, interpretables, buenos para relaciones lineales
- **Random Forest**: Mejor para relaciones no-lineales, maneja bien outliers
- **Gradient Boosting**: Muy potente, puede sobreajustar si no se controla

El sistema prueba todos y elige el mejor segÃºn RÂ² Score.

### 3. **Por quÃ© Auto-estimaciÃ³n?**
No todos los usuarios tienen todos los datos. El sistema es inteligente:
- Si falta `attendance`: busca eventos similares y promedia
- Si faltan `visitor_increase_pct`, etc.: usa promedios histÃ³ricos

Esto hace el sistema mÃ¡s accesible.

### 4. **Por quÃ© Baseline Comparison?**
Un evento puede generar $50M, pero si una semana normal genera $100M, el evento es peor que lo normal. La comparaciÃ³n con baseline da contexto real.

### 5. **Por quÃ© Ratios Fijos (64/25/11)?**
Son estÃ¡ndares de la industria econÃ³mica. En el futuro se podrÃ­an calcular dinÃ¡micamente, pero para MVP es suficiente.

---

## ğŸš€ CÃ³mo Mejorar el Sistema

### 1. **Mejorar Datos** âœ… **MEJORADO**
- âœ… **COMPLETADO**: Ahora usa los 7 CSVs (3 bÃ¡sicos + 4 de mÃ©tricas)
- AÃ±adir mÃ¡s eventos histÃ³ricos a los CSVs
- Asegurar que todos tengan `total_economic_impact_usd`
- AÃ±adir mÃ¡s ciudades
- Expandir rango de fechas en los CSVs de mÃ©tricas

### 2. **Mejorar Modelo** âœ… **MEJORADO**
- âœ… **COMPLETADO**: Ahora usa ~45 features en lugar de 13
- âœ… **COMPLETADO**: Features reales desde datos time-series
- Ajustar hiperparÃ¡metros de cada algoritmo
- Probar mÃ¡s algoritmos (XGBoost, Neural Networks)
- Feature engineering mÃ¡s avanzado (interacciones entre features)
- ValidaciÃ³n cruzada mÃ¡s robusta
- **Esperado**: MAPE deberÃ­a bajar significativamente (de ~45% a <20%)

### 3. **Mejorar Estimaciones**
- Calcular ratios 64/25/11 dinÃ¡micamente usando economic_metrics.csv
- Mejorar estimaciÃ³n de baseline usando datos reales de tourism_metrics.csv
- Ajustar $40K por empleo por regiÃ³n
- Calcular ROI real desde economic_metrics.csv

### 4. **Mejorar UX**
- Mostrar eventos similares usados en la predicciÃ³n
- Explicar por quÃ© se eligieron esos eventos
- Mostrar confianza por feature (cuÃ¡les son mÃ¡s inciertos)
- Mostrar quÃ© mÃ©tricas vienen de datos reales vs estimadas

---

## ğŸ“ Resumen Ejecutivo

**Archivos Clave:**
1. `endpoints.py`: API REST, maneja requests
2. `schemas.py`: ValidaciÃ³n de datos
3. `economic_impact_model.py`: â­ LÃ³gica completa del ML
4. `main.py`: ConfiguraciÃ³n FastAPI
5. **CSVs (7 archivos)**:
   - 3 bÃ¡sicos: events.csv, cities.csv, event_impacts.csv
   - 4 de mÃ©tricas: tourism_metrics.csv, hotel_metrics.csv, economic_metrics.csv, mobility_metrics.csv

**Flujo:**
1. Usuario â†’ Frontend â†’ POST /predict
2. FastAPI valida â†’ Llama modelo ML
3. Modelo busca eventos similares â†’ Estima parÃ¡metros
4. Modelo predice impacto â†’ Calcula KPIs
5. Retorna respuesta completa â†’ Frontend muestra

**CaracterÃ­sticas Clave:**
- Auto-entrenamiento si no existe modelo
- Auto-estimaciÃ³n de parÃ¡metros faltantes
- ComparaciÃ³n con baseline
- MÃºltiples algoritmos, elige el mejor
- Persistencia del modelo entrenado
- â­ **NUEVO**: Usa 7 CSVs (3 bÃ¡sicos + 4 de mÃ©tricas time-series)
- â­ **NUEVO**: ~45 features en lugar de 13 (mejor precisiÃ³n esperada)
- â­ **NUEVO**: Features reales desde datos histÃ³ricos diarios

---

Â¿Quieres que profundice en alguna parte especÃ­fica o que explique cÃ³mo mejorar algÃºn aspecto en particular?

