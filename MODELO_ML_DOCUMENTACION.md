# Modelo de Machine Learning para Predicci√≥n de Impacto Econ√≥mico de Eventos

## üìä Resumen Ejecutivo

Se desarroll√≥ un modelo de regresi√≥n para predecir el impacto econ√≥mico total de eventos bas√°ndose en caracter√≠sticas del evento, la ciudad y m√©tricas hist√≥ricas. El modelo final alcanza un **R¬≤ Score de 0.9719** y un **MAPE de 11.63%** utilizando **14 features optimizadas** y **1,102 observaciones**.

---

## 1. Generaci√≥n de Datos Sint√©ticos

### 1.1 Datos Iniciales

**Importante**: Existe una diferencia fundamental entre los registros de los CSVs y los eventos:

- **CSVs de m√©tricas time-series**: 4 archivos con **5,856 registros diarios cada uno**
  - Cada registro = 1 d√≠a √ó 1 ciudad
  - 16 ciudades √ó 366 d√≠as (2024, a√±o bisiesto) = 5,856 registros
  - `tourism_metrics.csv`: Visitantes, gasto por visitante, duraci√≥n de estancia
  - `hotel_metrics.csv`: Ocupaci√≥n, precios de hoteles
  - `economic_metrics.csv`: Gasto total y por categor√≠a
  - `mobility_metrics.csv`: Llegadas a aeropuertos, transporte p√∫blico, congesti√≥n

- **Eventos hist√≥ricos reales**: 12 eventos con impactos econ√≥micos verificados
  - Cada evento = 1 entidad con fecha de inicio, fin y duraci√≥n (puede durar varios d√≠as)
  - Estos eventos **usan** los datos de los CSVs para enriquecer sus m√©tricas

**¬øPor qu√© solo 1,102 eventos si hay 5,856 registros diarios?**

Los CSVs contienen datos **diarios** (un registro por d√≠a por ciudad), mientras que los eventos son **entidades** que:
- Pueden durar varios d√≠as (1-14 d√≠as t√≠picamente)
- Se generan en fechas espec√≠ficas a lo largo del a√±o
- Usan m√∫ltiples registros diarios de los CSVs para calcular m√©tricas agregadas

**Ejemplo**:
- Un evento de 7 d√≠as en Londres usa: 7 registros del CSV (uno por cada d√≠a del evento) + 30 registros del baseline (30 d√≠as antes)
- De los 5,856 registros diarios disponibles, se generaron 1,102 eventos distribuidos a lo largo del a√±o 2024

### 1.2 Metodolog√≠a de Generaci√≥n
Se generaron eventos sint√©ticos adicionales siguiendo estos pasos:

1. **An√°lisis de eventos reales**: Se calcularon factores de impacto por tipo de evento:
   - **Sports**: $211.29 por asistente total del evento
   - **Culture**: $1,399.77 por asistente total del evento
   - **Music**: $839.98 por asistente total del evento
   - **Festival**: $2,135.60 por asistente total del evento
   
   **Nota importante**: Estos factores representan el **impacto econ√≥mico total del evento dividido por el n√∫mero total de asistentes**, no por d√≠a. Por ejemplo:
   - Un evento Sports con 50,000 asistentes genera: 50,000 √ó $211.29 = $10.56M de impacto base
   - Este impacto se multiplica por 1.7 (multiplicador econ√≥mico) = $17.96M total
   
   **Relaci√≥n con la duraci√≥n**: El factor por asistente es **independiente de la duraci√≥n** en la f√≥rmula de generaci√≥n. Sin embargo, el modelo de ML **S√ç aprende** la relaci√≥n entre duraci√≥n e impacto porque tiene `duration_days` y `attendance_per_day` como features. El modelo observa que:
   - Eventos de 1-5 d√≠as: Factor promedio ~$1,500-2,000 por asistente
   - Eventos de 7-14 d√≠as: Factor promedio ~$300-600 por asistente (menor intensidad diaria)
   
   Por lo tanto, si predices un evento de 3 d√≠as vs uno de 6 d√≠as con la misma asistencia, el modelo **NO divide entre 2**, sino que aprende autom√°ticamente que eventos m√°s cortos tienden a tener mayor impacto por asistente debido a la mayor intensidad diaria.

2. **Extracci√≥n de m√©tricas reales desde CSVs**: Para cada evento sint√©tico:
   - **Per√≠odo del evento**: Se obtuvieron todos los registros diarios del CSV correspondientes a las fechas del evento
     - Ejemplo: Evento del 15-21 de enero en Londres = 7 registros de cada CSV
   - **Per√≠odo baseline**: Se obtuvieron registros de 30 d√≠as antes del evento (para comparaci√≥n)
     - Ejemplo: Baseline = 30 registros del 16 de diciembre al 14 de enero
   - **Agregaci√≥n**: Se calcularon promedios, m√°ximos y diferencias de estos registros diarios
   - **C√°lculo de ratios**: Se calcularon aumentos porcentuales comparando evento vs baseline

**Proceso de enriquecimiento**:
- Cada evento usa m√∫ltiples registros diarios de los CSVs (d√≠as del evento + d√≠as baseline)
- Los 5,856 registros diarios se "consumen" para generar m√©tricas agregadas por evento
- Un mismo registro diario puede ser usado por m√∫ltiples eventos si est√°n cerca en el tiempo

3. **C√°lculo de impacto econ√≥mico**:
   - **M√©todo 1**: Si hab√≠a datos econ√≥micos reales, se us√≥ el gasto adicional √ó multiplicador 1.7
   - **M√©todo 2**: Si no, se us√≥ la f√≥rmula: `attendance √ó factor_tipo_evento √ó 1.7`
   - Se aplic√≥ variaci√≥n aleatoria controlada (¬±15%) para realismo

4. **Validaci√≥n de consistencia**: 
   - Se ajustaron eventos generados para mantener consistencia con eventos reales
   - Se eliminaron outliers extremos
   - Se asegur√≥ rango realista: $1M - $5B

### 1.3 Resultado Final
- **Total de observaciones**: 1,102 eventos
  - 12 eventos reales
  - 1,090 eventos sint√©ticos generados
- **Distribuci√≥n**: Eventos distribuidos a lo largo de 2024 en 16 ciudades y 6 tipos de eventos
- **Uso de datos de CSVs**: 
  - Cada evento usa m√∫ltiples registros diarios de los CSVs (d√≠as del evento + 30 d√≠as baseline)
  - Los 5,856 registros diarios por CSV se utilizan para calcular m√©tricas agregadas por evento
  - **Ratio aproximado**: ~5-10 registros diarios por evento (dependiendo de la duraci√≥n)

---

## 2. Modelos Evaluados

Se entrenaron y compararon **5 algoritmos de regresi√≥n**:

| Modelo | Descripci√≥n | Ventajas |
|--------|-------------|----------|
| **Linear Regression** | Regresi√≥n lineal simple | R√°pido, interpretable |
| **Ridge Regression** | Regresi√≥n con regularizaci√≥n L2 | Maneja multicolinealidad |
| **Lasso Regression** | Regresi√≥n con regularizaci√≥n L1 | Selecci√≥n autom√°tica de features |
| **Random Forest** | Ensemble de √°rboles de decisi√≥n | Maneja relaciones no-lineales |
| **Gradient Boosting** | Boosting secuencial de √°rboles | Alta precisi√≥n, robusto |

### 2.1 Proceso de Entrenamiento
1. **Transformaci√≥n logar√≠tmica** del target (`log(1 + y)`) para manejar la distribuci√≥n sesgada
2. **Split 80/20**: 881 muestras entrenamiento, 221 muestras test
3. **Normalizaci√≥n**: StandardScaler para todas las features
4. **Validaci√≥n cruzada**: 5-fold CV para evaluar robustez

---

## 3. Selecci√≥n del Modelo Final

### 3.1 Comparaci√≥n de Resultados

| Modelo | R¬≤ Score | MAPE | MAE | RMSE | CV R¬≤ |
|--------|----------|------|-----|------|-------|
| Linear Regression | 0.3821 | 70.32% | $199.3M | $350.1M | 0.5534 |
| Ridge Regression | 0.3968 | 70.43% | $198.0M | $345.9M | 0.5541 |
| Lasso Regression | 0.3828 | 96.01% | $198.1M | $349.9M | 0.4987 |
| Random Forest | 0.8889 | 16.23% | $70.6M | $148.5M | 0.9602 |
| **Gradient Boosting** | **0.9719** | **11.63%** | **$39.6M** | **$74.7M** | **0.9811** |

### 3.2 Modelo Seleccionado: Gradient Boosting

**Razones de selecci√≥n**:
- ‚úÖ **Mayor R¬≤ Score** (0.9719): Explica el 97.19% de la varianza
- ‚úÖ **Menor MAPE** (11.63%): Error porcentual promedio m√°s bajo
- ‚úÖ **Menor MAE y RMSE**: Predicciones m√°s precisas
- ‚úÖ **Alta validaci√≥n cruzada** (0.9811): Modelo robusto y generalizable

**Hiperpar√°metros**:
- `n_estimators`: 100
- `max_depth`: 5
- `learning_rate`: 0.1
- `random_state`: 42

---

## 4. Optimizaci√≥n de Features

### 4.1 An√°lisis Inicial
- **Features iniciales**: 40
- **Problema detectado**: Alta correlaci√≥n entre features (>0.9 en 47 pares)
- **Features redundantes**: Muchas m√©tricas derivadas conten√≠an informaci√≥n similar

### 4.2 Metodolog√≠a de Reducci√≥n

1. **An√°lisis de correlaci√≥n**: Identificaci√≥n de pares con correlaci√≥n >0.9
2. **Importancia de features**: C√°lculo usando Gradient Boosting
3. **Selecci√≥n estad√≠stica**: SelectKBest con f_regression
4. **Eliminaci√≥n de redundantes**: 
   - Se mantuvo la feature m√°s importante de cada par correlacionado
   - Se eliminaron features con importancia <0.001

### 4.3 Features Eliminadas (26)

**Ejemplos de eliminaciones**:
- `visitor_increase_pct` (correlaci√≥n 0.9995 con `price_increase_pct`)
- `baseline_avg_total_visitors` (correlaci√≥n 0.9989 con `baseline_avg_airport_arrivals`)
- `event_avg_daily_spending` (correlaci√≥n 0.9922 con `event_avg_total_visitors`)
- `event_avg_food_spending`, `event_avg_retail_spending` (correlaci√≥n >0.99)
- M√∫ltiples m√©tricas de movilidad redundantes

### 4.4 Features Finales (14)

| Feature | Importancia | Descripci√≥n |
|---------|-------------|-------------|
| `attendance` | 68.36% | Asistencia al evento |
| `event_type_encoded` | 29.69% | Tipo de evento (sports, music, etc.) |
| `event_max_hotel_price` | 0.48% | Precio m√°ximo de hotel durante evento |
| `event_avg_hotel_price` | 0.27% | Precio promedio de hotel |
| `visitor_increase_actual` | 0.24% | Aumento real de visitantes (desde CSVs) |
| `daily_spending_increase_pct` | 0.21% | Aumento porcentual de gasto diario |
| `event_avg_accommodation_spending` | 0.18% | Gasto promedio en alojamiento |
| `event_avg_public_transport` | 0.16% | Uso de transporte p√∫blico |
| `baseline_avg_spending_per_visitor` | 0.13% | Gasto promedio por visitante (baseline) |
| `attendance_per_day` | 0.12% | Asistencia promedio diaria |
| `duration_days` | - | Duraci√≥n del evento en d√≠as |
| `visitors_per_hotel_room` | - | Ratio visitantes/habitaciones |
| `hotel_rooms` | - | N√∫mero de habitaciones disponibles |
| `city_tourism_intensity` | - | Intensidad tur√≠stica de la ciudad |

### 4.5 Resultados de la Optimizaci√≥n

| M√©trica | 40 Features | 14 Features | Mejora |
|---------|-------------|-------------|--------|
| **R¬≤ Score** | 0.9602 | **0.9719** | **+1.17%** |
| **MAPE** | 12.11% | **11.63%** | **-0.48%** |
| **MAE** | $45.1M | **$39.6M** | **-$5.5M** |
| **RMSE** | $88.8M | **$74.7M** | **-$14.1M** |

**Beneficios**:
- ‚úÖ **65% menos features** (de 40 a 14)
- ‚úÖ **Mejor precisi√≥n** en todas las m√©tricas
- ‚úÖ **Modelo m√°s r√°pido** y eficiente
- ‚úÖ **Menor riesgo de sobreajuste**

---

## 5. Evoluci√≥n del Dataset

### 5.1 Incremento de Observaciones

| Iteraci√≥n | Observaciones | R¬≤ Score | MAPE | Descripci√≥n |
|-----------|---------------|----------|------|-------------|
| Inicial | 12 | 0.4452 | 338.62% | Solo eventos reales |
| Primera generaci√≥n | 112 | 0.9646 | 185.26% | +100 eventos sint√©ticos |
| Segunda generaci√≥n | 491 | 0.9602 | 12.11% | +379 eventos de calidad |
| Optimizaci√≥n final | 1,102 | **0.9719** | **11.63%** | +611 eventos + ajustes |

### 5.2 Impacto del Aumento de Datos

- **De 12 a 112 eventos**: Mejora dram√°tica (MAPE: 338% ‚Üí 185%)
- **De 112 a 491 eventos**: Mejora significativa (MAPE: 185% ‚Üí 12%)
- **De 491 a 1,102 eventos**: Mejora final (MAPE: 12.11% ‚Üí 11.63%)

**Conclusi√≥n**: El aumento de observaciones fue cr√≠tico para mejorar el modelo, especialmente de 12 a 491 eventos.

---

## 6. C√°lculo de Empleos Creados

### 6.1 Metodolog√≠a Mejorada

Inicialmente se usaba un ratio fijo de **$40,000 por empleo** para todos los eventos. Tras analizar los 1,102 eventos hist√≥ricos, se identific√≥ que el ratio var√≠a significativamente seg√∫n la **ciudad** debido a diferencias en el costo de vida y salarios:

| Ciudad | Ratio (USD por empleo) | Observaciones |
|--------|------------------------|---------------|
| **Paris** | $47,475 | Mayor costo (18.7% m√°s que Chicago) |
| **New York** | $43,102 | Alto costo de vida |
| **Berlin** | $42,426 | Costo medio-alto |
| **London** | $41,727 | Costo medio-alto |
| **Madrid** | $40,383 | Costo medio |
| **Tokyo** | $40,315 | Costo medio |
| **Miami** | $40,005 | Costo medio-bajo |
| **S√£o Paulo** | $40,007 | Costo bajo |
| **Chicago** | $40,001 | Menor costo |

**Diferencia**: Paris ($47,475) vs Chicago ($40,001) = **18.7% m√°s caro**

### 6.2 Implementaci√≥n

El modelo ahora calcula `jobs_created` usando el ratio espec√≠fico de la ciudad **ajustado por la duraci√≥n del evento**:

```python
# Antes (ratio fijo, sin considerar duraci√≥n):
jobs_created = int(prediction / 40000)

# Ahora (ratio por ciudad ajustado por duraci√≥n):
# El ratio base ($40,000) representa el costo de un empleo a tiempo completo durante 1 a√±o (250 d√≠as laborables)
# Para eventos de duraci√≥n corta, ajustamos: (ratio_base / 250) * duration_days
jobs_ratio_base = jobs_ratios_by_city.get(city_name, 40000)
jobs_ratio_adjusted = (jobs_ratio_base / 250) * duration_days
jobs_created = int(prediction / jobs_ratio_adjusted)
```

**Ejemplo**:
- Evento en Paris (ratio base: $47,475/a√±o) de 7 d√≠as
- Ratio ajustado: ($47,475 / 250) √ó 7 = $1,329.30 por empleo
- Si el impacto es $10M: jobs_created = 10,000,000 / 1,329.30 ‚âà 7,525 empleos

### 6.3 ¬øAfecta el Modelo ML?

**NO**. El ratio de $40,000 (o el espec√≠fico por ciudad) **NO se usa en el entrenamiento del modelo ML**. 

- El modelo ML predice `total_economic_impact_usd` bas√°ndose en features como `attendance`, `event_type`, `duration_days`, etc.
- **Despu√©s** de la predicci√≥n, se calcula `jobs_created = prediction / jobs_ratio`
- Es un c√°lculo **post-predicci√≥n** para mostrar m√©tricas adicionales al usuario
- No afecta la precisi√≥n del modelo (R¬≤, MAPE, etc.)

### 6.4 Transparencia en el Frontend

El frontend ahora muestra el ratio espec√≠fico usado para cada predicci√≥n:
- **Antes**: "Estimated at $40,000 per job created" (fijo)
- **Ahora**: "Estimated at $47,475 per job created" (din√°mico seg√∫n ciudad, ej: Paris)

Esto proporciona mayor transparencia y precisi√≥n en las estimaciones.

---

## 7. M√©tricas Finales del Modelo

### 6.1 Rendimiento en Test Set (221 eventos)

| M√©trica | Valor | Interpretaci√≥n |
|---------|-------|----------------|
| **R¬≤ Score** | **0.9719** | El modelo explica el 97.19% de la varianza |
| **MAPE** | **11.63%** | Error porcentual promedio del 11.63% |
| **MAE** | **$39.6M** | Error absoluto promedio de $39.6 millones |
| **RMSE** | **$74.7M** | Error cuadr√°tico medio de $74.7 millones |

### 6.2 Validaci√≥n Cruzada (5-fold)

- **CV R¬≤**: 0.9811 ¬± 0.0058
- **Interpretaci√≥n**: El modelo es robusto y generaliza bien (baja varianza entre folds)

### 6.3 Feature Importance

Las dos features m√°s importantes explican el **98.05%** de la importancia total:
- `attendance`: 68.36%
- `event_type_encoded`: 29.69%

---

## 8. Conclusiones

### 7.1 Logros Principales

1. ‚úÖ **Alta precisi√≥n**: R¬≤ Score de 0.9719 y MAPE de 11.63%
2. ‚úÖ **Modelo optimizado**: Reducci√≥n de 40 a 14 features sin p√©rdida de precisi√≥n
3. ‚úÖ **Dataset robusto**: 1,102 observaciones con datos sint√©ticos de alta calidad
4. ‚úÖ **Validaci√≥n s√≥lida**: CV R¬≤ de 0.9811 indica excelente generalizaci√≥n

### 7.2 Contribuciones Clave

- **Generaci√≥n inteligente de datos**: Uso de m√©tricas reales de CSVs para crear eventos sint√©ticos consistentes
- **Optimizaci√≥n de features**: Eliminaci√≥n sistem√°tica de redundancias mejor√≥ el modelo
- **Selecci√≥n de algoritmo**: Gradient Boosting demostr√≥ ser superior para este problema

### 7.3 Limitaciones y Mejoras Futuras

- **Datos sint√©ticos**: Aunque basados en datos reales, no reemplazan eventos hist√≥ricos verificados
- **Mejora potencial**: Recolectar m√°s eventos reales para validaci√≥n adicional
- **Hiperpar√°metros**: Podr√≠an ajustarse m√°s finamente con grid search

---

## 9. Reproducibilidad

### 8.1 Archivos de Datos
- `data/examples/events.csv`: 1,102 eventos
- `data/examples/event_impacts.csv`: Impactos econ√≥micos
- `data/examples/cities.csv`: Caracter√≠sticas de ciudades
- `data/examples/tourism_metrics.csv`: M√©tricas de turismo (5,856 registros)
- `data/examples/hotel_metrics.csv`: M√©tricas de hoteles (5,856 registros)
- `data/examples/economic_metrics.csv`: M√©tricas econ√≥micas (5,856 registros)
- `data/examples/mobility_metrics.csv`: M√©tricas de movilidad (5,856 registros)

### 8.2 Modelo Guardado
- `backend/app/ml/saved_models/economic_impact_model.pkl`
- Incluye: modelo entrenado, scaler, label encoders, m√©tricas

### 8.3 Scripts de Entrenamiento
- `backend/train_model.py`: Script principal de entrenamiento
- `generate_quality_events.py`: Generaci√≥n de eventos sint√©ticos
- `analyze_and_reduce_features.py`: An√°lisis y reducci√≥n de features

---

**Versi√≥n del documento**: 1.0  
**Fecha**: 2024  
**Modelo final**: Gradient Boosting Regressor  
**R¬≤ Score**: 0.9719  
**MAPE**: 11.63%

